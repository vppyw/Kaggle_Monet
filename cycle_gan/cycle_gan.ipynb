{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f100a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import itertools\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac7f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fcf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, tfm=tfm):\n",
    "        super(ImgDataset, self).__init__()\n",
    "        self.tfm = tfm\n",
    "        self.content_list = [os.path.join(os.getcwd(), './dataset/photo_jpg/', file) for file in os.listdir('./dataset/photo_jpg/')]\n",
    "        self.style_list = [os.path.join(os.getcwd(), './dataset/monet_jpg/', file) for file in os.listdir('./dataset/monet_jpg/')]\n",
    "        self.len = len(self.content_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        content = Image.open(self.content_list[idx])\n",
    "        content = self.tfm(content)\n",
    "        style = Image.open(random.choice(self.style_list))\n",
    "        style = self.tfm(style)\n",
    "        return style, content\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class SampleDataset(Dataset):\n",
    "    def __init__(self, path, tfm=tfm, mx_len=64):\n",
    "        super(SampleDataset, self).__init__()\n",
    "        self.tfm = tfm\n",
    "        self.file_list = [os.path.join(os.getcwd(), path, file) for file in os.listdir(path)][:mx_len]\n",
    "        self.len = mx_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = Image.open(self.file_list[idx])\n",
    "        x = self.tfm(x)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf7a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_istn_lrelu(in_dim, out_dim, ist_norm=True):\n",
    "    if ist_norm:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim,\n",
    "                      out_channels=out_dim,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(out_dim, affine = True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim,\n",
    "                      out_channels=out_dim,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "def convt_istn_relu(in_dim, out_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=in_dim,\n",
    "                          out_channels=out_dim,\n",
    "                          kernel_size=4, stride=2, padding=1),\n",
    "        nn.InstanceNorm2d(out_dim, affine=True),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.weight.data.normal_(mean=0.0, std=1.0)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean=0.0, std=1.0)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        m.weight.data.normal_(mean=0.0, std=1.0)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ae = nn.Sequential(\n",
    "            conv_istn_lrelu(3, 64, ist_norm = False),\n",
    "            conv_istn_lrelu(64, 128),\n",
    "            conv_istn_lrelu(128, 256),\n",
    "            conv_istn_lrelu(256, 256),\n",
    "            conv_istn_lrelu(256, 256),\n",
    "            conv_istn_lrelu(256, 256),\n",
    "            conv_istn_lrelu(256, 256),\n",
    "            convt_istn_relu(256, 256),\n",
    "            convt_istn_relu(256, 256),\n",
    "            convt_istn_relu(256, 256),\n",
    "            convt_istn_relu(256, 256),\n",
    "            convt_istn_relu(256, 128),\n",
    "            convt_istn_relu(128, 64),\n",
    "            nn.ConvTranspose2d(in_channels=64,\n",
    "                              out_channels=3,\n",
    "                              kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ae(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006bb2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            conv_istn_lrelu(3, 64),\n",
    "            conv_istn_lrelu(64, 128),\n",
    "            conv_istn_lrelu(128, 256),\n",
    "            conv_istn_lrelu(256, 256),\n",
    "            conv_istn_lrelu(256, 256),\n",
    "            conv_istn_lrelu(256, 256),\n",
    "            conv_istn_lrelu(256, 256),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "        self.apply(init_weights)\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.fc(x.view(x.size()[0], -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    def __init__(self):\n",
    "        self.config = {\n",
    "            \"name\":\"cycleGAN\",\n",
    "            \"device\": \"cuda:1\" if torch.cuda.is_available() else \"cpu\",\n",
    "            \"epoch\": 50,\n",
    "            \"batch_size\": 16,\n",
    "            \"g_lr\": 1e-4,\n",
    "            \"m_d_lr\": 1e-4,\n",
    "            \"p_d_lr\": 1e-4,\n",
    "        }\n",
    "        \n",
    "        # dataloader\n",
    "        dataset = ImgDataset()\n",
    "        self.dataloader = DataLoader(dataset, batch_size=self.config[\"batch_size\"], shuffle=True, num_workers=8)\n",
    "        \n",
    "        photo_dataset = SampleDataset('./dataset/photo_jpg')\n",
    "        self.photoloader = DataLoader(photo_dataset, batch_size=self.config[\"batch_size\"], shuffle=False, num_workers=8)\n",
    "        \n",
    "        monet_dataset = SampleDataset('./dataset/monet_jpg')\n",
    "        self.monetloader = DataLoader(monet_dataset, batch_size=self.config[\"batch_size\"], shuffle=False, num_workers=8)\n",
    "\n",
    "        # models\n",
    "        self.M2P = Generator().to(self.config[\"device\"])\n",
    "        self.M_D = Discriminator().to(self.config[\"device\"])\n",
    "        self.P2M = Generator().to(self.config[\"device\"])\n",
    "        self.P_D = Discriminator().to(self.config[\"device\"])\n",
    "        \n",
    "        # optimizer\n",
    "        self.opt_G = torch.optim.Adam(itertools.chain(self.M2P.parameters(), self.P2M.parameters()), lr=self.config[\"g_lr\"], betas=(0.5, 0.999))\n",
    "        self.opt_M_D = torch.optim.Adam(self.M_D.parameters(), lr=self.config[\"m_d_lr\"], betas=(0.5, 0.999))\n",
    "        self.opt_P_D = torch.optim.Adam(self.P_D.parameters(), lr=self.config[\"p_d_lr\"], betas=(0.5, 0.999))\n",
    "        \n",
    "        # loss\n",
    "        self.L1 = nn.L1Loss()\n",
    "        self.L2 = nn.MSELoss()\n",
    "        \n",
    "        os.makedirs(f'cycle_checkpoints/', exist_ok=True)\n",
    "        \n",
    "    def train(self):\n",
    "        for e in range(self.config[\"epoch\"]):\n",
    "            M_D_loss = []\n",
    "            P_D_loss = []\n",
    "            id_loss_list = []\n",
    "            GAN_loss_list = []\n",
    "            cycle_loss_list = []\n",
    "\n",
    "            for m, p in tqdm(self.dataloader):\n",
    "                m = m.to(self.config[\"device\"])\n",
    "                p = p.to(self.config[\"device\"])\n",
    "\n",
    "                # Discriminator Monet\n",
    "                r_logits = self.M_D(m)\n",
    "                f_logits = self.M_D(self.P2M(p).detach())\n",
    "                loss_D = self.L2(r_logits, torch.ones_like(r_logits)) +\\\n",
    "                            self.L2(f_logits, torch.zeros_like(f_logits))\n",
    "                self.opt_M_D.zero_grad()\n",
    "                loss_D.backward()\n",
    "                self.opt_M_D.step()\n",
    "                M_D_loss += [loss_D.item()]\n",
    "                \n",
    "                # Discrminator Photo\n",
    "                r_logits = self.P_D(p)\n",
    "                f_logits = self.P_D(self.M2P(m).detach())\n",
    "                loss_D = self.L2(r_logits, torch.ones_like(r_logits).to(self.config[\"device\"])) +\\\n",
    "                            self.L2(f_logits, torch.zeros_like(f_logits).to(self.config[\"device\"]))\n",
    "                self.opt_P_D.zero_grad()\n",
    "                loss_D.backward()\n",
    "                self.opt_P_D.step()\n",
    "                P_D_loss += [loss_D.item()]\n",
    "                \n",
    "                # Generator\n",
    "                m_prime = self.P2M(m)\n",
    "                p_prime = self.M2P(p)\n",
    "                m_f = self.P2M(p)\n",
    "                p_f = self.M2P(m)\n",
    "                m_rec = self.P2M(p_f)\n",
    "                p_rec = self.M2P(m_f)\n",
    "                \n",
    "                m_logits = self.M_D(m_f).detach()\n",
    "                p_logits = self.P_D(p_f).detach()\n",
    "                \n",
    "                id_loss = self.L1(m_prime, m) + self.L1(p_prime, p)\n",
    "                gan_loss = self.L2(m_logits, torch.ones_like(m_logits).to(self.config[\"device\"])) +\\\n",
    "                            self.L2(p_logits, torch.ones_like(p_logits).to(self.config[\"device\"]))\n",
    "                cycle_loss = self.L2(m_rec, m) + self.L2(p_rec, p)\n",
    "                \n",
    "                id_loss_list += [id_loss.item()]\n",
    "                GAN_loss_list += [gan_loss.item()]\n",
    "                cycle_loss_list += [cycle_loss.item()]\n",
    "                \n",
    "                loss_G = id_loss * 1e5 + gan_loss + cycle_loss * 1e5\n",
    "                self.opt_G.zero_grad()\n",
    "                loss_G.backward()\n",
    "                self.opt_G.step()\n",
    "            print(f\"M_D: {mean(M_D_loss):.5e}\")\n",
    "            print(f\"P_D: {mean(P_D_loss): .5e}\")\n",
    "            print(f\"identity loss:{mean(id_loss_list):.5e}\")\n",
    "            print(f\"GAN loss:{mean(GAN_loss_list):.5e}\")\n",
    "            print(f\"cycle loss:{mean(cycle_loss_list):.5e}\")\n",
    "            if e % 10 == 0:\n",
    "                torch.save(self.M2P, f\"cycle_checkpoints/M2P_{e}.pt\")\n",
    "                torch.save(self.M2P, f\"cycle_checkpoints/P2M_{e}.pt\")\n",
    "                os.makedirs(f'cycle_logs/epoch_{e}', exist_ok=True)\n",
    "                \n",
    "                x = None\n",
    "                y = None\n",
    "                for p in self.photoloader:\n",
    "                    p = p.to(self.config[\"device\"])\n",
    "                    p2p = (self.M2P(self.P2M(p)).data + 1) / 2\n",
    "                    p2m = (self.P2M(p).data + 1) / 2\n",
    "                    for _x, _y in zip(p2p, p2m):\n",
    "                        if x == None: x = _x.unsqueeze(0).to('cpu')\n",
    "                        else: x = torch.cat((x, _x.unsqueeze(0).to('cpu')), 0)\n",
    "                        if y == None: y = _y.unsqueeze(0).to('cpu')\n",
    "                        else: y = torch.cat((y, _y.unsqueeze(0).to('cpu')), 0)\n",
    "                torchvision.utils.save_image(x, f\"cycle_logs/epoch_{e}/p2p.jpg\", nrow=8)\n",
    "                torchvision.utils.save_image(x, f\"cycle_logs/epoch_{e}/p2m.jpg\", nrow=8)\n",
    "                \n",
    "                x = None\n",
    "                y = None\n",
    "                for m in self.monetloader:\n",
    "                    m = m.to(self.config[\"device\"])\n",
    "                    m2m = (self.P2M(self.M2P(m)).data + 1) / 2\n",
    "                    m2p = (self.P2M(m).data + 1) / 2\n",
    "                    for _x, _y in zip(m2m, m2p):\n",
    "                        if x == None: x = _x.unsqueeze(0).to('cpu')\n",
    "                        else: x = torch.cat((x, _x.unsqueeze(0).to('cpu')), 0)\n",
    "                        if y == None: y = _y.unsqueeze(0).to('cpu')\n",
    "                        else: y = torch.cat((y, _y.unsqueeze(0).to('cpu')), 0)\n",
    "                torchvision.utils.save_image(x, f\"cycle_logs/epoch_{e}/m2m.jpg\", nrow=8)\n",
    "                torchvision.utils.save_image(x, f\"cycle_logs/epoch_{e}/m2p.jpg\", nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CycleGAN()\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
